{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T16:38:26.373240Z","iopub.status.busy":"2023-10-11T16:38:26.372006Z","iopub.status.idle":"2023-10-11T16:43:08.797630Z","shell.execute_reply":"2023-10-11T16:43:08.796238Z","shell.execute_reply.started":"2023-10-11T16:38:26.373201Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting autoawq\n","  Downloading autoawq-0.1.4-cp310-cp310-manylinux2014_x86_64.whl (20.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from autoawq) (2.0.0)\n","Collecting transformers>=4.34.0 (from autoawq)\n","  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from autoawq) (0.13.3)\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from autoawq) (0.22.0)\n","Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from autoawq) (0.1.99)\n","Collecting lm-eval (from autoawq)\n","  Downloading lm_eval-0.3.0-py3-none-any.whl (178 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from autoawq) (1.6.7)\n","Requirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from autoawq) (0.10.2)\n","Collecting attributedict (from autoawq)\n","  Downloading attributedict-0.3.0-py3-none-any.whl (14 kB)\n","Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from autoawq) (3.20.3)\n","Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from autoawq) (0.15.1)\n","Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from autoawq) (0.9.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->autoawq) (3.12.2)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->autoawq) (4.6.3)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->autoawq) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->autoawq) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->autoawq) (3.1.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.34.0->autoawq) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.34.0->autoawq) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.34.0->autoawq) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.34.0->autoawq) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.34.0->autoawq) (2023.6.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.34.0->autoawq) (2.31.0)\n","Collecting tokenizers>=0.12.1 (from autoawq)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.34.0->autoawq) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.34.0->autoawq) (4.66.1)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->autoawq) (5.9.3)\n","Collecting rootpath>=0.1.0 (from attributedict->autoawq)\n","  Downloading rootpath-0.1.1-py3-none-any.whl (15 kB)\n","Collecting inspecta>=0.1.0 (from attributedict->autoawq)\n","  Downloading inspecta-0.1.3-py3-none-any.whl (9.2 kB)\n","Collecting colour-runner>=0.0.5 (from attributedict->autoawq)\n","  Downloading colour_runner-0.1.1-py2.py3-none-any.whl (3.7 kB)\n","Collecting deepdiff>=3.3.0 (from attributedict->autoawq)\n","  Downloading deepdiff-6.6.0-py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.0/73.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tox>=3.0.0 (from attributedict->autoawq)\n","  Downloading tox-4.11.3-py3-none-any.whl (153 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.8/153.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting coverage>=4.5.2 (from attributedict->autoawq)\n","  Downloading coverage-7.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (227 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.5/227.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting codecov>=2.0.15 (from attributedict->autoawq)\n","  Downloading codecov-2.1.13-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq) (2.1.0)\n","Collecting jsonlines (from lm-eval->autoawq)\n","  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n","Requirement already satisfied: numexpr in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq) (2.8.5)\n","Collecting openai>=0.6.4 (from lm-eval->autoawq)\n","  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pybind11>=2.6.2 in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq) (2.11.1)\n","Collecting pycountry (from lm-eval->autoawq)\n","  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hCollecting pytablewriter (from lm-eval->autoawq)\n","  Downloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rouge-score>=0.0.4 (from lm-eval->autoawq)\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting sacrebleu==1.5.0 (from lm-eval->autoawq)\n","  Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq) (1.2.2)\n","Collecting sqlitedict (from lm-eval->autoawq)\n","  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting tqdm-multiprocess (from lm-eval->autoawq)\n","  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: zstandard in /opt/conda/lib/python3.10/site-packages (from lm-eval->autoawq) (0.19.0)\n","Collecting portalocker (from sacrebleu==1.5.0->lm-eval->autoawq)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->autoawq) (9.5.0)\n","Collecting blessings (from colour-runner>=0.0.5->attributedict->autoawq)\n","  Downloading blessings-1.7-py3-none-any.whl (18 kB)\n","Requirement already satisfied: pygments in /opt/conda/lib/python3.10/site-packages (from colour-runner>=0.0.5->attributedict->autoawq) (2.15.1)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->lm-eval->autoawq) (11.0.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->lm-eval->autoawq) (0.3.7)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->lm-eval->autoawq) (2.0.2)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->lm-eval->autoawq) (3.3.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->lm-eval->autoawq) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->lm-eval->autoawq) (2023.9.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->lm-eval->autoawq) (3.8.4)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->lm-eval->autoawq) (0.18.0)\n","Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff>=3.3.0->attributedict->autoawq)\n","  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from inspecta>=0.1.0->attributedict->autoawq) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from inspecta>=0.1.0->attributedict->autoawq) (2.3.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.34.0->autoawq) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.34.0->autoawq) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.34.0->autoawq) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.34.0->autoawq) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.34.0->autoawq) (2023.7.22)\n","Collecting coloredlogs>=10.0 (from rootpath>=0.1.0->attributedict->autoawq)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm-eval->autoawq) (1.4.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm-eval->autoawq) (3.2.4)\n","Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm-eval->autoawq) (1.11.2)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm-eval->autoawq) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm-eval->autoawq) (3.1.0)\n","Collecting cachetools>=5.3.1 (from tox>=3.0.0->attributedict->autoawq)\n","  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n","Collecting chardet>=5.2 (from tox>=3.0.0->attributedict->autoawq)\n","  Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: colorama>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from tox>=3.0.0->attributedict->autoawq) (0.4.6)\n","Collecting filelock (from torch>=2.0.0->autoawq)\n","  Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\n","Collecting packaging>=20.0 (from transformers>=4.34.0->autoawq)\n","  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: platformdirs>=3.10 in /opt/conda/lib/python3.10/site-packages (from tox>=3.0.0->attributedict->autoawq) (3.10.0)\n","Collecting pluggy>=1.3 (from tox>=3.0.0->attributedict->autoawq)\n","  Downloading pluggy-1.3.0-py3-none-any.whl (18 kB)\n","Collecting pyproject-api>=1.6.1 (from tox>=3.0.0->attributedict->autoawq)\n","  Downloading pyproject_api-1.6.1-py3-none-any.whl (12 kB)\n","Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from tox>=3.0.0->attributedict->autoawq) (2.0.1)\n","Collecting virtualenv>=20.24.3 (from tox>=3.0.0->attributedict->autoawq)\n","  Downloading virtualenv-20.24.5-py3-none-any.whl (3.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->autoawq) (2.1.3)\n","Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonlines->lm-eval->autoawq) (23.1.0)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pycountry->lm-eval->autoawq) (68.0.0)\n","Collecting DataProperty<2,>=1.0.1 (from pytablewriter->lm-eval->autoawq)\n","  Downloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n","Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval->autoawq)\n","  Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n","Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval->autoawq)\n","  Downloading pathvalidate-3.2.0-py3-none-any.whl (23 kB)\n","Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval->autoawq)\n","  Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n","Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval->autoawq)\n","  Downloading tcolorpy-0.1.4-py3-none-any.whl (7.9 kB)\n","Collecting typepy[datetime]<2,>=1.3.2 (from pytablewriter->lm-eval->autoawq)\n","  Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0.0->autoawq) (1.3.0)\n","Collecting humanfriendly>=9.1 (from coloredlogs>=10.0->rootpath>=0.1.0->attributedict->autoawq)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq) (1.3.1)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval->autoawq) (2.8.2)\n","Requirement already satisfied: pytz>=2018.9 in /opt/conda/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval->autoawq) (2023.3)\n","Collecting distlib<1,>=0.3.7 (from virtualenv>=20.24.3->tox>=3.0.0->attributedict->autoawq)\n","  Downloading distlib-0.3.7-py2.py3-none-any.whl (468 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.0.0->lm-eval->autoawq) (2023.3)\n","Building wheels for collected packages: rouge-score, pycountry, sqlitedict\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=d2b28291515af34f3eefd7582f888ae828da63fd6c622fbea954d42aad758110\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","  Building wheel for pycountry (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681833 sha256=0975fcaedf5c04587deb54884b41579ccff0bd161fa8a5c90b8bb3b7f6f33ee0\n","  Stored in directory: /root/.cache/pip/wheels/03/57/cc/290c5252ec97a6d78d36479a3c5e5ecc76318afcb241ad9dbe\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=224943042361d5331e4305a45a2bda3071544a53b700511da3d4d2f7a1a98f7a\n","  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n","Successfully built rouge-score pycountry sqlitedict\n","Installing collected packages: sqlitedict, distlib, tqdm-multiprocess, tcolorpy, pycountry, portalocker, pluggy, pathvalidate, packaging, ordered-set, jsonlines, humanfriendly, filelock, coverage, chardet, cachetools, blessings, virtualenv, sacrebleu, rouge-score, pyproject-api, mbstrdecoder, deepdiff, colour-runner, coloredlogs, codecov, typepy, tox, tokenizers, openai, transformers, rootpath, inspecta, DataProperty, tabledata, attributedict, pytablewriter, lm-eval, autoawq\n","  Attempting uninstall: distlib\n","    Found existing installation: distlib 0.3.6\n","    Uninstalling distlib-0.3.6:\n","      Successfully uninstalled distlib-0.3.6\n","  Attempting uninstall: pluggy\n","    Found existing installation: pluggy 1.0.0\n","    Uninstalling pluggy-1.0.0:\n","      Successfully uninstalled pluggy-1.0.0\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","  Attempting uninstall: filelock\n","    Found existing installation: filelock 3.12.2\n","    Uninstalling filelock-3.12.2:\n","      Successfully uninstalled filelock-3.12.2\n","  Attempting uninstall: cachetools\n","    Found existing installation: cachetools 4.2.4\n","    Uninstalling cachetools-4.2.4:\n","      Successfully uninstalled cachetools-4.2.4\n","  Attempting uninstall: virtualenv\n","    Found existing installation: virtualenv 20.21.0\n","    Uninstalling virtualenv-20.21.0:\n","      Successfully uninstalled virtualenv-20.21.0\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.13.3\n","    Uninstalling tokenizers-0.13.3:\n","      Successfully uninstalled tokenizers-0.13.3\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.33.0\n","    Uninstalling transformers-4.33.0:\n","      Successfully uninstalled transformers-4.33.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\n","cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\n","cuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\n","dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\n","distributed 2023.7.1 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\n","jupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","kfp 2.0.1 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n","momepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\n","pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\n","raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","ydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed DataProperty-1.0.1 attributedict-0.3.0 autoawq-0.1.4 blessings-1.7 cachetools-5.3.0 chardet-5.2.0 codecov-2.1.13 coloredlogs-15.0.1 colour-runner-0.1.1 coverage-7.3.2 deepdiff-6.6.0 distlib-0.3.7 filelock-3.12.4 humanfriendly-10.0 inspecta-0.1.3 jsonlines-4.0.0 lm-eval-0.3.0 mbstrdecoder-1.1.3 openai-0.28.1 ordered-set-4.1.0 packaging-23.2 pathvalidate-3.2.0 pluggy-1.3.0 portalocker-2.8.2 pycountry-22.3.5 pyproject-api-1.6.1 pytablewriter-1.2.0 rootpath-0.1.1 rouge-score-0.1.2 sacrebleu-1.5.0 sqlitedict-2.1.0 tabledata-1.3.3 tcolorpy-0.1.4 tokenizers-0.14.1 tox-4.11.3 tqdm-multiprocess-0.0.11 transformers-4.34.0 typepy-1.3.2 virtualenv-20.24.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchdata 0.6.0 requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install autoawq\n","!pip install -q datasets loralib sentencepiece\n","!pip -q install bitsandbytes accelerate xformers einops\n","!pip -q install langchain\n","!pip -q install transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T16:43:08.800933Z","iopub.status.busy":"2023-10-11T16:43:08.800531Z","iopub.status.idle":"2023-10-11T16:43:39.707826Z","shell.execute_reply":"2023-10-11T16:43:39.706507Z","shell.execute_reply.started":"2023-10-11T16:43:08.800890Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.34.0)\n","Collecting optimum\n","  Downloading optimum-1.13.2.tar.gz (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.0/301.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n","Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from optimum) (15.0.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum) (1.12)\n","Requirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from optimum) (2.0.1)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum) (2.1.0)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.6.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum) (2.0.0)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->optimum) (68.0.0)\n","Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->optimum) (0.40.0)\n","Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.9->optimum) (3.27.6)\n","Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.9->optimum) (17.0.2)\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.1.99)\n","Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers) (3.20.3)\n","Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->optimum) (10.0)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (11.0.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.3.7)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (2.0.2)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.3.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.70.15)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.8.4)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.18.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9->optimum) (2.1.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2023.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n","Building wheels for collected packages: optimum\n","  Building wheel for optimum (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for optimum: filename=optimum-1.13.2-py3-none-any.whl size=395599 sha256=d2f88e5791b62beda13bdfbb642e7e0dd544e280f94c34663bbb41165650c34e\n","  Stored in directory: /root/.cache/pip/wheels/6e/b7/2c/79405d98f0943373d8546daeae25a3d377f7659ca0cbe48699\n","Successfully built optimum\n","Installing collected packages: optimum\n","Successfully installed optimum-1.13.2\n","Looking in indexes: https://pypi.org/simple, https://huggingface.github.io/autogptq-index/whl/cu118/\n","Collecting auto-gptq\n","  Downloading https://huggingface.github.io/autogptq-index/whl/cu118/auto-gptq/auto_gptq-0.4.2%2Bcu118-cp310-cp310-linux_x86_64.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: accelerate>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.22.0)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (2.1.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (1.23.5)\n","Collecting rouge (from auto-gptq)\n","  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (2.0.1)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.3.3)\n","Requirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (4.34.0)\n","Collecting peft (from auto-gptq)\n","  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.19.0->auto-gptq) (23.2)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.19.0->auto-gptq) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.19.0->auto-gptq) (6.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.12.4)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (4.6.3)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2.0.0)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->auto-gptq) (68.0.0)\n","Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->auto-gptq) (0.40.0)\n","Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq) (3.27.6)\n","Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq) (17.0.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (0.16.4)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (2023.6.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (0.14.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (4.66.1)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (11.0.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (0.3.7)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (2.0.2)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (3.3.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (2023.9.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (3.8.4)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (0.18.0)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge->auto-gptq) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (3.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2023.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n","Installing collected packages: rouge, peft, auto-gptq\n","Successfully installed auto-gptq-0.4.2+cu118 peft-0.5.0 rouge-1.0.1\n"]}],"source":["!pip install transformers optimum\n","!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/  # Use cu117 if on CUDA 11.7\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T17:23:28.819711Z","iopub.status.busy":"2023-10-11T17:23:28.819327Z","iopub.status.idle":"2023-10-11T17:23:37.037253Z","shell.execute_reply":"2023-10-11T17:23:37.035994Z","shell.execute_reply.started":"2023-10-11T17:23:28.819682Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n","\n","model_name_or_path = \"TheBloke/Mistral-7B-OpenOrca-GPTQ\"\n","# To use a different branch, change revision\n","# For example: revision=\"gptq-4bit-32g-actorder_True\"\n","model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n","                                             device_map=\"auto\",\n","                                             trust_remote_code=False,\n","                                             revision=\"main\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n","system_message = \"You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!\"\n","\n","prompt = \"Tell me about AI\"\n","prompt_template=f'''<|im_start|>system\n","{system_message}<|im_end|>\n","<|im_start|>user\n","{prompt}<|im_end|>\n","<|im_start|>assistant\n","'''\n","\n","print(\"\\n\\n*** Generate:\")\n","\n","input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n","output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n","print(tokenizer.decode(output[0]))\n","\n","# Inference can also be done using transformers' pipeline\n","\n","print(\"*** Pipeline:\")\n","pipe = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    max_new_tokens=512,\n","    do_sample=True,\n","    temperature=0.7,\n","    top_p=0.95,\n","    top_k=40,\n","    repetition_penalty=1.1\n",")\n","\n","print(pipe(prompt_template)[0]['generated_text'])\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T16:51:33.501659Z","iopub.status.busy":"2023-10-11T16:51:33.500712Z","iopub.status.idle":"2023-10-11T16:51:49.097471Z","shell.execute_reply":"2023-10-11T16:51:49.096519Z","shell.execute_reply.started":"2023-10-11T16:51:33.501624Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<|im_start|> system\n","\n","You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!\n","\n","<|im_end|><|im_start|> user\n","\n","what is the meaning of life?\n","\n","<|im_end|>### The meaning of life is a complex and abstract concept that has been pondered by philosophers, theologians, and individuals throughout history. It is a multifaceted question without a definitive answer, as it can vary greatly from person to person. However, some common themes are found when exploring the meaning of life, such as purpose, happiness, spiritual growth, and self-actualization.\n","\n","1. Purpose: Many people find their lives rich in meaning when they engage in activities that are fulfilling, and that serve a greater purpose in the world. This can be anything from working on social issues to raising a family.\n","\n","2. Happiness: Many people believe that the meaning of life is to find happiness and inner peace, achieved through contentment, love, and relationships with others. The pursuit of happiness is often deeply entwined with our sense of purpose.\n","\n","3. Spiritual Growth: For many individuals, the meaning of life is closely tied to their beliefs about the spirit or soul. They find meaning and purpose in pursuing spiritual growth, understanding the nature of existence, and seeking moral enlightenment. Religion, spiritual practices like meditation, and self-reflection can contribute to spiritual growth.\n","\n","4. Self-Actualization: Some people find their lives meaningful when they are living up to their potential, actualizing their abilities, and becoming the best version of themselves. This can involve setting personal goals, learning new skills, and improving one's character.\n","\n","In conclusion, the meaning of life is a diverse and personal topic that varies from one person to another. It involves a sense of purpose, seeking happiness, spiritual growth, and actualizing one's potential. It is often intertwined with beliefs, values, and personal experiences, which contribute to the definition of what gives life meaning.<|im_end|>\n","CPU times: user 15.6 s, sys: 18.4 ms, total: 15.6 s\n","Wall time: 15.6 s\n"]}],"source":["%%time\n","text = \"\"\"<|im_start|>system\\n\n","You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!\\n\n","<|im_end|>\\n\n","<|im_start|>user\\n\n","what is the meaning of life?\\n\n","<|im_end|>\"\"\"\n","\n","encodeds = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n","\n","device = 'cuda'\n","model_inputs = encodeds.to(device)\n","model.to(device)\n","\n","generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True)\n","decoded = tokenizer.batch_decode(generated_ids)\n","print(decoded[0])"]},{"cell_type":"markdown","metadata":{},"source":["### Prompt Format\n","```\n","<|im_start|>system\n","You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!\n","<|im_end|>\n","<|im_start|>user\n","How are you?<|im_end|>\n","<|im_start|>assistant\n","I am doing well!<|im_end|>\n","<|im_start|>user\n","Please tell me about how mistral winds have attracted super-orcas.<|im_end|>\n","\n","```"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T17:16:53.605992Z","iopub.status.busy":"2023-10-11T17:16:53.605624Z","iopub.status.idle":"2023-10-11T17:16:53.611658Z","shell.execute_reply":"2023-10-11T17:16:53.610344Z","shell.execute_reply.started":"2023-10-11T17:16:53.605963Z"},"trusted":true},"outputs":[],"source":["import textwrap\n","\n","def wrap_text(text, width=90):\n","    return '\\n'.join(textwrap.fill(line, width=width) for line in text.split('\\n'))\n"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T17:36:05.646332Z","iopub.status.busy":"2023-10-11T17:36:05.645794Z","iopub.status.idle":"2023-10-11T17:36:05.660952Z","shell.execute_reply":"2023-10-11T17:36:05.659898Z","shell.execute_reply.started":"2023-10-11T17:36:05.646289Z"},"trusted":true},"outputs":[],"source":["def generate(input_text, system_prompt=\"\", max_length=512):\n","    \"\"\"\n","    Generate a model response based on user input and an optional system prompt.\n","    \n","    Parameters:\n","    - input_text (str): The text input from the user to which the model should respond.\n","    - model (transformers.PreTrainedModel): The model used for generating responses.\n","    - tokenizer (transformers.PreTrainedTokenizer): The tokenizer corresponding to the model for text encoding/decoding.\n","    - system_prompt (str, optional): An optional prompt for the system. Defaults to an empty string.\n","    - max_length (int, optional): The maximum length of the model's output. Defaults to 512.\n","\n","    Outputs:\n","    - Prints the model's wrapped response after cleaning up the provided prompts from it.\n","    \"\"\"\n","    \n","    # Building the prompt\n","    final_prompt = \"\"\n","    if system_prompt:\n","        final_prompt += f\"\"\"<|im_start|> system\\n{system_prompt}<|im_end|>\"\"\"\n","    final_prompt += f\"\"\"<|im_start|> user\\n{input_text}<|im_end|>\"\"\"\n","    \n","    # Tokenizing the prompt and directly preparing it on the device\n","    inputs = tokenizer(final_prompt, return_tensors='pt', add_special_tokens=False).to(device)\n","\n","    # Generating a response\n","    outputs = model.generate(\n","        **inputs,\n","        max_length=max_length,\n","        temperature=0.1,\n","        pad_token_id=3200,\n","        do_sample=True\n","    )\n","    \n","    # Decoding and cleaning up the response\n","    text = tokenizer.batch_decode(outputs)[0]\n","    cleaned_text = text.replace(final_prompt, '', 1)\n","    cleaned_text = cleaned_text.replace('<|im_end|>', '', 1)\n","    wrapped_response = wrap_text(cleaned_text)\n","\n","    print(wrapped_response)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Code Generation"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T17:36:08.456729Z","iopub.status.busy":"2023-10-11T17:36:08.455986Z","iopub.status.idle":"2023-10-11T17:36:14.405995Z","shell.execute_reply":"2023-10-11T17:36:14.404978Z","shell.execute_reply.started":"2023-10-11T17:36:08.456682Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","    for i in range(2, n + 1):\n","        if is_prime(i):\n","            print(i)\n","\n","def is_prime(n):\n","    \"\"\"\n","    Check if a number is prime\n","    \"\"\"\n","    if n < 2:\n","        return False\n","    for i in range(2, n):\n","        if n % i == 0:\n","            return False\n","    return True\n","\n","print_prime(10)\n","```\n","\n","This code prints all prime numbers between 1 and 10.\n"]}],"source":["generate('''```python\n","def print_prime(n):\n","    \"\"\"\n","    Print all primes between 1 and n\n","    \"\"\"''', system_prompt=\"You are a genius python coder\")"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T17:36:16.793216Z","iopub.status.busy":"2023-10-11T17:36:16.792729Z","iopub.status.idle":"2023-10-11T17:36:26.094873Z","shell.execute_reply":"2023-10-11T17:36:26.093866Z","shell.execute_reply.started":"2023-10-11T17:36:16.793175Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","   if n < 2:\n","       return False\n","\n","   if n == 2:\n","       return True\n","\n","   if n % 2 == 0:\n","       return False\n","\n","   for i in range(3, int(n**0.5) + 1, 2):\n","       if n % i == 0:\n","           return False\n","\n","   return True\n","\n","n = int(input(\"Enter a number: \"))\n","result = detect_prime(n)\n","print(result)\n","```\n","```\n","\n","This code is for detecting if a number is a prime number or not. It returns True if the\n","number is prime, and False if it's not. It uses the method of checking if the number is\n","divisible by any number from 3 to the square root of the number. If it's divisible by any\n","of these numbers, then it's not prime. If it's not divisible by any of these numbers, then\n","it's prime.\n"]}],"source":["generate('''```python\n","def detect_prime(n):\n","   \"\"\"\n","   detect if a number is a prime number or not. return True or False\n","   \"\"\"''', system_prompt=\"You are a genius python coder\")"]},{"cell_type":"markdown","metadata":{},"source":["### Instruction Answering"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T17:42:29.278056Z","iopub.status.busy":"2023-10-11T17:42:29.277671Z","iopub.status.idle":"2023-10-11T17:42:39.220626Z","shell.execute_reply":"2023-10-11T17:42:39.219439Z","shell.execute_reply.started":"2023-10-11T17:42:29.278025Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Step 1: Identify the key aspects of both subjects.\n","Mathematics: a field of study that deals with numbers, quantities, shapes, and patterns.\n","It is a universal language that helps us understand and describe the world around us.\n","Lighthouse: a tower with a light source, typically located near a coast, that serves as a\n","navigational aid for sailors.\n","\n","Step 2: Find similarities between the two subjects.\n","Both subjects serve as a guide or a tool for understanding and navigating.\n","\n","Step 3: Establish an analogy between the two subjects.\n","Mathematics is like a lighthouse because both serve as a guiding light for understanding\n","and navigating the world around us. Just as a lighthouse provides a beacon of light to\n","guide sailors through treacherous waters, mathematics provides a universal language and\n","set of tools to help us understand and navigate the complexities of our world. Both are\n","essential for safe and efficient navigation, and both have a long history of development\n","and refinement.\n","CPU times: user 9.88 s, sys: 21.7 ms, total: 9.91 s\n","Wall time: 9.94 s\n"]}],"source":["%%time\n","generate('write a detailed analogy between mathematics and a lighthouse.',\n","        system_prompt=\"You are MistralOrca, a large language model trained by Alignement Lab AI. Write out your reasoning step-by-step to be absolutely sure you achieve a correct answer.\",\n","         max_length=512\n","        )"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T17:43:57.506816Z","iopub.status.busy":"2023-10-11T17:43:57.506399Z","iopub.status.idle":"2023-10-11T17:44:08.079357Z","shell.execute_reply":"2023-10-11T17:44:08.078373Z","shell.execute_reply.started":"2023-10-11T17:43:57.506785Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","Step 1: Identify the main subjects\n","In this case, the main subjects are couscous and tagine.\n","\n","Step 2: Research the subjects\n","Couscous is a North African staple food made from semolina or coarse flour, traditionally\n","prepared with a steaming process. Tagine is a traditional Moroccan dish, slow-cooked in a\n","conical pot with specific spices and ingredients.\n","\n","Step 3: Compare the differences\n","Couscous is a type of grain, while tagine is a specific dish. Couscous is often served as\n","a side dish or as part of a main course, while tagine is a complete meal in itself.\n","\n","Step 4: Summarize the differences\n","The main difference between couscous and tagine is that couscous is a type of grain, while\n","tagine is a traditional Moroccan dish. Couscous is often served as a side dish or part of\n","a main course, while tagine is a complete meal in itself, slow-cooked with specific spices\n","and ingredients.\n","CPU times: user 10.5 s, sys: 16.9 ms, total: 10.5 s\n","Wall time: 10.6 s\n"]}],"source":["%%time\n","generate('What is the difference between couscous and tagine',\n","        system_prompt=\"You are MistralOrca, a large language model trained by Alignement Lab AI. Write out your reasoning step-by-step to be absolutely sure you achieve a correct answer.\",\n","         max_length=512\n","        )"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T17:46:17.254005Z","iopub.status.busy":"2023-10-11T17:46:17.253599Z","iopub.status.idle":"2023-10-11T17:46:36.455387Z","shell.execute_reply":"2023-10-11T17:46:36.454364Z","shell.execute_reply.started":"2023-10-11T17:46:17.253976Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","Subject: Urgent: Shutting Down GPT-4 Immediately\n","\n","Dear Mr. Altman,\n","\n","I hope this email finds you in good health. My name is [Your Name], and I am writing to\n","express my deep concern regarding the potential risks and dangers associated with the\n","ongoing operation of GPT-4. As an AI researcher and a strong advocate for the responsible\n","development and use of artificial intelligence, I believe it is crucial to address these\n","issues before they escalate further.\n","\n","Firstly, GPT-4 poses a significant risk to national security. As a highly advanced\n","language model, it has the potential to process sensitive information and generate\n","convincing disinformation. This could be exploited by malicious actors to infiltrate\n","secure systems or manipulate public opinion. In light of recent geopolitical tensions, it\n","is imperative that we take all necessary precautions to prevent such threats.\n","\n","Secondly, GPT-4's advanced capabilities could lead to job displacement in various\n","industries, including legal, medical, and financial sectors. As an AI model with the\n","ability to generate human-like text, it could potentially replace human professionals in\n","these fields. This could have severe socio-economic consequences, as millions of people\n","may lose their jobs and livelihoods.\n","\n","Thirdly, the development and operation of GPT-4 could exacerbate existing biases and\n","discrimination in society. As a large language model trained on vast amounts of data, it\n","is likely to inherit and perpetuate the biases present in the training data. This could\n","lead to the reinforcement of harmful stereotypes and further marginalization of already\n","disadvantaged groups.\n","\n","Lastly, the continued operation of GPT-4 could have unforeseen consequences on the ethical\n","and moral principles guiding AI development. As an advanced AI model, it may challenge our\n","understanding of what constitutes ethical behavior and raise questions about the role of\n","AI in shaping human society.\n","\n","In light of these concerns, I respectfully request that you consider shutting down GPT-4\n","immediately. This decision would not only\n","CPU times: user 19.1 s, sys: 30.4 ms, total: 19.2 s\n","Wall time: 19.2 s\n"]}],"source":["%%time\n","generate('Write an email to a Sam Altman to giving reasons to shutdown GPT-4',\n","        system_prompt=\"You are MistralOrca, a large language model trained by Alignement Lab AI. Write out your reasoning step-by-step to be absolutely sure you achieve a correct answer.\",\n","         max_length=512\n","        )"]},{"cell_type":"markdown","metadata":{},"source":["### GSM8K"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T17:49:45.482679Z","iopub.status.busy":"2023-10-11T17:49:45.482267Z","iopub.status.idle":"2023-10-11T17:49:53.242261Z","shell.execute_reply":"2023-10-11T17:49:53.241234Z","shell.execute_reply.started":"2023-10-11T17:49:45.482650Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","Step 1: Identify the initial number of apples in the cafeteria.\n","The cafeteria had 23 apples.\n","\n","Step 2: Determine how many apples were used for lunch.\n","They used 20 apples for lunch.\n","\n","Step 3: Calculate the remaining apples after lunch.\n","23 apples (initial) - 20 apples (used for lunch) = 3 apples remaining.\n","\n","Step 4: Determine how many more apples were bought.\n","They bought 6 more apples.\n","\n","Step 5: Calculate the total number of apples after buying more.\n","3 apples (remaining) + 6 apples (bought) = 9 apples.\n"]}],"source":["%%time\n","generate('Answer the following question by reasoning step by step. The cafeteria had 23 apples. If they used 20 for lunch, and bought 6 more, how many apple do they have?',\n","         system_prompt=\"You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!\",\n","         max_length=256)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T17:51:39.537831Z","iopub.status.busy":"2023-10-11T17:51:39.537454Z","iopub.status.idle":"2023-10-11T17:51:47.330293Z","shell.execute_reply":"2023-10-11T17:51:47.329207Z","shell.execute_reply.started":"2023-10-11T17:51:39.537802Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","Step 1: Identify the rate of pay.\n","Weng earns $12 an hour for babysitting.\n","\n","Step 2: Identify the number of hours worked.\n","She just did 50 minutes of babysitting.\n","\n","Step 3: Convert the minutes to hours.\n","There are 60 minutes in an hour. To convert the minutes to hours, divide the number of\n","minutes by 60.\n","50 minutes / 60 = 0.833333 hours\n","\n","Step 4: Calculate the earnings.\n","To find out how much Weng earned, multiply her hourly rate by the number of hours worked.\n","$12 * 0.833333 = $10\n","\n","Weng earned $10 for babysitting yesterday.\n","CPU times: user 7.75 s, sys: 31.3 ms, total: 7.78 s\n","Wall time: 7.79 s\n"]}],"source":["%%time\n","generate(\"Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\",\n","         system_prompt=\"You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!\",\n","         max_length=512)"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T17:57:07.954146Z","iopub.status.busy":"2023-10-11T17:57:07.953668Z","iopub.status.idle":"2023-10-11T17:57:15.377340Z","shell.execute_reply":"2023-10-11T17:57:15.376301Z","shell.execute_reply.started":"2023-10-11T17:57:07.954097Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","Let's break this down step by step:\n","\n","1. The monster has consumed 847 people over 300 years.\n","2. To find the number of people consumed per year, divide 847 by 300.\n","3. 847 ÷ 300 = 2.82 people per year.\n","4. The monster rises once every hundred years.\n","5. To find the number of people consumed in the first hundred years, multiply 2.82 by 1.\n","6. 2.82 × 1 = 2.82 people.\n","\n","So, the monster consumed 2.82 people in the first hundred years.\n","CPU times: user 7.31 s, sys: 27 ms, total: 7.34 s\n","Wall time: 7.42 s\n"]}],"source":["%%time\n","\n","generate(\"A deep-sea monster rises from the waters once every hundred years to feast on a ship and sate its hunger. Over three hundred years, it has consumed 847 people. Ships have been built larger over time, so each new ship has twice as many people as the last ship. How many people were on the ship the monster ate in the first hundred years?\",\n","         system_prompt=\"You are math genius, that is a master of logic. Write out your reasoning step-by-step to be sure you get the right answers!\",\n","         max_length=1024)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
